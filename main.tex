%% The first command in your LaTeX source must be the \documentclass command.
%%
%% Options:
%% twocolumn : Two column layout.
%% hf: enable header and footer.
\documentclass[
twocolumn,
% hf,
]{ceurart}

%%
%% One can fix some overfulls
\sloppy

%%
%% Minted listings support 
%% Need pygment <http://pygments.org/> <http://pypi.python.org/pypi/Pygments>
\usepackage{minted}
%% auto break lines
\setminted{breaklines=true}

\usepackage[a4paper]{geometry}
% \usepackage{clic2023} % imports CLiC-it 2023 layout style
\usepackage{times} % font
\usepackage{xurl} % splits URL in multiple lines
\usepackage[italian,english]{babel}
\usepackage{latexsym}
\pagenumbering{gobble} % does not display page numbering
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{todonotes}
\usepackage{subcaption}
\usepackage{amssymb}
\usepackage{float}
\usepackage{cuted}
\usepackage{soul}
\usepackage{xcolor}
\usepackage{ulem}

\definecolor{lightgreen}{RGB}{0, 180, 0}
\definecolor{lightred}{RGB}{214, 0, 0}

\newcommand{\hlg}[1]{{\sethlcolor{lightgreen}\hl{#1}}}
\newcommand{\hlr}[1]{{\sethlcolor{lightred}\hl{#1}}}


\newcommand{\bs}[0]{$\blacksquare$}

\newcommand{\Ni}{(\textit{i})~}
\newcommand{\Nii}{(\textit{ii})~}
\newcommand{\Niii}{(\textit{iii})~}

\newcommand{\abc}[1]{{\color{blue} #1}}
\newcommand{\paolo}[1]{{\color{red} #1}}

\newcommand{\todoA}[1]{\todo[color=blue!40]{A: #1}}
\newcommand{\todoP}[1]{\todo[color=red]{P: #1}}

\newcommand{\itodo}[1]{\todo[inline]{#1}}

\newcommand{\dsENcorpus}{IFU-22-EN}
\newcommand{\dsITcorpus}{IFU-22-IT}
\newcommand{\dsENclassification}{IFS-EN}
\newcommand{\dsITclassification}{IFS-IT}
\newcommand{\dsENforecasting}{IFSS-EN-223K}
\newcommand{\dsITforecasting}{IFSS-IT-30K}

\newcommand{\bert}{\mbox{BERT$_{base}$}}
\newcommand{\mbert}{\mbox{mBERT$_{base}$}}
\newcommand{\imbert}{\mbox{Incel mBERT}}
\newcommand{\umbert}{\mbox{UmBERTo}}
\newcommand{\albert}{\mbox{AlBERTo}}
\newcommand{\iumbert}{\mbox{Incel UmBERTo}}
\newcommand{\ialbert}{\mbox{Incel AlBERTo}}

\newcommand{\hsdfb}{\mbox{HSD-FB}}
\newcommand{\hsdtw}{\mbox{HSD-TW}}
\newcommand{\ami}{\mbox{AMI-20}}


\newcommand{\dsENclassificationtrain}{IFS-EN$_{\mbox{tr}}$} % Incel Forum Supervised, English, 5203 instances
\newcommand{\dsENclassificationdev}{IFS-EN$_{\mbox{de}}$} % Incel Forum Supervised, English, 5203 instances
\newcommand{\dsENclassificationtest}{IFS-EN$_{\mbox{te}}$} % Incel Forum Supervised, English, 5203 instances

\newcommand{\enforum}{\textit{Incels.is}}
\newcommand{\itforum}{\textit{Il forum dei brutti}}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% Rights management information.
%% CC-BY is default license.
\copyrightyear{2023}
\copyrightclause{Copyright for this paper by its authors.
  Use permitted under Creative Commons License Attribution 4.0
  International (CC BY 4.0).}

%%
%% This command is for the conference information
\conference{CLiC-it 2023: 9th Italian Conference on Computational Linguistics, Nov 30 — Dec 02, 2023, Venice, Italy}

%%
%% The "title" command
\title{Hate Speech Detection in an Italian Incel Forum Using Bilingual Data for Pre-Training and Fine-Tuning}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
\author[1]{Paolo Gajo}[%
orcid=0009-0009-9372-3323,
email=paolo.gajo2@unibo.it,
url=https://www.unibo.it/sitoweb/paolo.gajo2,
]

\author[1]{Silvia Bernardini}[%
orcid=0000-0003-0750-4861,
email=silvia.bernardini@unibo.it,
url=https://www.unibo.it/sitoweb/silvia.bernardini,
]

\author[1]{Adriano Ferraresi}[%
orcid=0000-0002-6957-0605,
email=adriano.ferraresi@unibo.it,
url=https://www.unibo.it/sitoweb/adriano.ferraresi,
]

\author[1]{Alberto Barr\'on-Cede\~no}[%
orcid=0000-0003-4719-3420,
email=a.barron@unibo.it,
url=https://www.unibo.it/sitoweb/a.barron,
]

\address[1]{Department of Interpreting and Translation, Universit\`a di Bologna, Corso della Repubblica, 136, 47121, Forl\`i, FC, Italy}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract} 
\textbf{\textbf{English.}} In this study, we aim to enhance hate speech detection in Italian incel posts.
We pre-train monolingual (Italian) and multilingual Transformer models on corpora built from two incel forums, one in Italian and one in English, using masked language modeling. Then, we fine-tune the models on combinations of English and Italian corpora, annotated for hate speech.
Experiments on a hate speech corpus derived from the Italian incel forum show that the best results are achieved by training multilingual models on bilingual data,
rather than training monolingual models on Italian-only data. This emphasizes the importance of using training and testing data from a similar linguistic domain, even when the languages differ.

\noindent
\textbf{Italiano.} \textit{In questo studio, ci proponiamo di migliorare il rilevamento dei discorsi d'odio in post tratti da un forum italiano di incel.
Addestriamo modelli Transformer mono (italiano) e multilingue su corpora ottenuti da due forum di incel, uno in italiano e uno in inglese, con il masked language modeling. Facciamo quindi il fine-tuning dei modelli su corpora in italiano e inglese con annotazioni indicanti se un post esprime odio.
Sperimentando su un corpus annotato per i discorsi di odio ottenuto da un forum italiano di incel mostriamo che i risultati migliori si ottengono addestrando modelli multilingue su combinazioni bilingue di corpora e non con modelli italiani e dati monolingue. Ciò sottolinea l'importanza di utilizzare dati di addestramento appartenenti a un contesto linguistico simile a quello dei dati di valutazione, anche con lingue differenti.}
\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\begin{keywords}
incels \sep
hate speech \sep
masked language modeling \sep
transformers \sep
bert \sep
multilingual mlm \sep
multilingual masked language modeling
\end{keywords}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}

While there is no scarcity of English-language models and training resources for
the detection of hate speech (HS), especially with the recent rise in popularity of
this research topic~\cite{alkomahLiteratureReviewTextual2022},
much work can still be carried out on this problem in other languages.
For less-resourced languages, such as Italian, one of the main difficulties of combating this phenomenon is the lack of annotated data~\cite{van2023mitigating}. The problem is even more severe when considering the detection of hate speech in niche contexts,
such as in forums frequented by incels,
short for ``involuntary celibates'', a community known for its hateful language \cite{nagle-2017-kill-normies,jakiOnlineHatredWomen2019}
and use of
specific misogynous and racist lexicon \cite{farrellExploringMisogynyManosphere2019,gothard2020exploring}.
In particular, it seems no work has yet been done on the detection of hate speech in Italian incel forums.

In this paper, we present a simple approach to improve the performance of hate speech detection models in Italian forums frequented by incels. Our contribution is two-fold:

\noindent\textbf{\Ni Masked language modeling.} We adapt monolingual Italian models to the linguistic domain of Italian incel forums by training them on the masked language modeling (MLM) task. As training material, we use an unlabelled corpus compiled from an Italian incel forum. We also adopt an existing multilingual model, already domain-adapted to the incel domain in both English and Italian.
We release these novel models, which can be used for further research on the topic.\footnote{Links to the models, released on HuggingFace: \url{https://github.com/paolo-gajo/clic23}.}

\noindent\textbf{\Nii Hate speech detection.}
We fine-tune the vanilla and domain-adapted models on the downstream task of detecting hate speech in Italian incel posts.
Monolingual models are trained on Italian-only combinations of corpora binary-annotated for hate speech, while Italian--English combinations are used for the multilingual models.

Testing the performance of the models on a labelled hate speech corpus, obtained by annotating posts from the Italian incel forum, shows that the best results are obtained by first training the base multilingual model on bilingual data taken from both the Italian and English incel forums, using the MLM task, and then fine-tuning it on combinations of Italian and English corpora, annotated for hate speech. In the approached scenarios, pre-training and fine-tuning on bilingual in-domain incel annotated data may therefore be more effective than training on general target-language labelled corpora, despite part of the training data not being in the language of the downstream task. In addition, the results show that this strategy can be used to improve model performance when in-domain target-language data is scarce, by using in-domain data from other languages.

The rest of the paper is organized as follows: Section~\ref{sec:related-work} presents related work on hate speech detection in Italian and English, as well as multilingual approaches to the problem. Section~\ref{sec:corpora} describes the corpora used in this study. Section~\ref{sec:models} presents the employed models. Section~\ref{sec:exps} describes the experiments conducted and discusses the results. Section~\ref{sec:conclusions} closes the contribution with conclusions and future work.

\section{Related Work}
\label{sec:related-work}

Prior work on Italian hate speech detection has been conducted chiefly within the context of EVALITA\@. The 2018 edition hosted a shared task on hate speech detection~\cite{boscoOverviewEVALITA2018} based on two corpora, one comprising tweets and one Facebook posts. The participating teams experimented with a variety of algorithms, with the top team relying on an SVM and a BiLSTM~\cite{cimino2018multi}. The 2020 edition hosted a shared task on the detection of hate speech, stereotypes, and nominal utterances, especially against migrants, focusing on tweets and news headlines~\cite{basileEVALITA2020Overview}. In this case,
the best team's approach for the hate speech detection sub-task \cite{Lavergne2020TheNorthH} was to fine-tune \bert\, \cite{devlin-etal-2019-bert} along with \albert\, \cite{PolignanoEtAlCLIC2019} and \umbert\, \cite{musixmatch-2020-umberto}, two BERT models pre-trained on Italian data.

As regards misogyny in particular, EVALITA 2018 hosted for the first time a shared task on automatic misogyny identification (AMI), where the top performing teams used a combination of TF-IDF and SVD for the Italian scenario, and TF-IDF with logistic regression for the English one~\cite{Fersini2018OverviewOT}.
EVALITA 2020 hosted the second edition of the AMI shared task, focusing on Italian tweets~\cite{fersiniAMIEVALITA2020Automatic2020}, where an ensemble of BERT models obtained the top performance~\cite{mutiUniBOAMIMultiClass2020}. In EVALITA 2023, \citet{bonaventura2023odang} used triple verbalisation, prompting and majority vote to improve the performance of an AlBERTo model on the tasks of homotransphobia and hate speech detection.

English-language hate speech detection has been conducted in a variety of ways. Among others, \citet{davidson-2017-automated-hate} build a corpus of tweets annotated with multi-class labels (``hate speech'', ``offensive'', ``neither'') and train logistic regression and linear SVM models on it.
\citet{mathew2021hatexplain} build a corpus called HateXplain from Twitter and Gab posts, annotated with multi-class labels based on whether the post is ``offensive'', expresses ``hate'', or is ``normal'', which they use to fine-tune a BERT hate speech classifier.
\citet{caselli-etal-2021-hatebert} retrain BERT$_{base}$ on the MLM task using an unlabelled corpus built from hateful and offensive Reddit messages, obtaining a model called HateBERT, capable of outperforming BERT$_{base}$ on hate speech identification on various benchmark datasets.

In multilingual settings, \citet{peliconInvestigatingCrosslingualTraining2021} use a multilingual combination of corpora annotated for hate speech to improve the performance of classifiers in zero-shot, few-shot and well-resourced settings. \citet{gokhaleSpreadLoveNot2022} use MLM training to improve the hate speech detection performance of BERT in Hindi and Marathi, separately. We follow such approaches in improving the performance of our models, with a specific focus on monolingual vs.\ bilingual pre-training, compared to \citet{gajo2023identification}.

\section{Corpora}
\label{sec:corpora}

We leverage three labelled Italian-language corpora from past EVALITA
campaigns, along with two labelled corpora compiled from two incel forums.
\paragraph{EVALITA corpora}
The first Italian corpus we use was compiled for the first edition of the Hate Speech Detection (HaSpeeDe) shared task, from EVALITA 2018~\cite{boscoOverviewEVALITA2018} (henceforth \hsdfb), by annotating Facebook posts for hate speech. The second one is from the 2020 edition of HaSpeeDe~\cite{Sanguinetti2020haspeedeeoverview} (\hsdtw), compiled by adding new data to the HaSpeeDe 2018 Twitter corpus. The third corpus is the one compiled for the Automatic Misogyny Identification (AMI) shared task~\cite{fersiniAMIEVALITA2020Automatic2020} (\ami), hosted at EVALITA 2020. \ami\, is annotated with misogyny labels, which we use as hate speech labels to train our classifiers.
Where the corpora were not partitioned,
we split them 
70/30 between training and development sets. We do not use the test partitions, as we are interested in maintaining consistency with the use of the original splits of these corpora.

\paragraph{Incel corpora}
We use two unlabelled corpora compiled by scraping two incel forums~\cite{gajo2023identification}: \textit{\enforum}\footnote{\url{https://incels.is} (Last access: 11 Aug 2023)} and \textit{\itforum}\footnote{\url{https://ilforumdeibrutti.forumfree.it} (Last access: 11 Aug 2023)}, respectively in English and Italian.

A subset of the two corpora was annotated for both misogyny and racism.\footnote{Refer to \citet{gajo2023identification} for details on the annotation process.}
The annotated partitions are referred to as \dsENclassification\, and \dsITclassification\, (``Incel Forum, Supervised, English'' and ``Italian'').

We keep the training, development and testing partitions as in the released corpora. \dsITclassification\, is used in its entirety solely as a test set, due to the unavailability of additional annotated Italian incel data for training. Said scarcity prompted us to leverage the available data in order to conduct cross-lingual experiments for the incel domain, for which Italian is a low-resource language.

\renewcommand{\arraystretch}{0.95}

\begin{table}[t]
  \caption{Existing corpora class distribution.}
  \label{tab:existing-corpora-distributions}
  \centering
  \begin{tabular}{l@{\hspace{1mm}}l|cc}
  \hline
  \bf Corpus          & & \bf HS &  \bf Non-HS \\
  \hline
  \ami\,              & \cite{fersiniAMIEVALITA2020Automatic2020} &  2,337 &  2,663  \\
  \hsdfb              & \cite{boscoOverviewEVALITA2018} &  1,382 &    1,617  \\
  \hsdtw              & \cite{boscoOverviewEVALITA2018} &  \,\,\,\,971   &  2,028   \\
  \hline
  \end{tabular}
\end{table}

Table~\ref{tab:existing-corpora-distributions} shows the class distribution of all three EVALITA corpora, whereas
Table~\ref{tab:incel-corpora-distributions} shows the distribution for the incel corpora, where posts are considered hateful if they are either labeled as misogynous or racist. As can be inferred from the statistics, while misogynous instances comprise around 39\% of the instances in both \dsENclassification\, and \dsITclassification, the same cannot be said for the racist ones, which are much more prevalent in \dsENclassification\, (13\% vs.\ 0.03\%). This shows a clear difference in terms of the hate speech produced by the two incel communities.

\section{Models}
\label{sec:models}
With relation to the Italian-only scenario, we use \umbert\, and \albert\, for our baseline models. We choose these models because they achieved the best performance in previous EVALITA shared tasks on hate speech~\cite{basileEVALITA2020Overview} and misogyny~\cite{fersiniAMIEVALITA2020Automatic2020} identification.
In order to improve the performance of the two models on the task of identifying hate speech in Italian incel forums, we train them on the MLM task on posts extracted from \itforum. We follow this approach because it has been shown to work in English both for general hateful content \cite{caselli-etal-2021-hatebert} and incel forums \cite{gajo2023identification}.
For training data, we use the entirety of the contents of the forum, for a total of $627k$ posts. The intersection between the unlabelled
incel corpora and the annotated corpora listed in Table~\ref{tab:incel-corpora-distributions} is void. That is, none of the data contained in \dsITclassification\, was obtained from the Italian data scraped from \itforum\, and used for MLM pre-training. The same is true for \dsENclassification\, and the English MLM pre-training data taken from \enforum.
Doing this, we obtain two new models which we refer to as ``\iumbert'' and ``\ialbert''.

The MLM pre-training process is carried out in all cases by tokenizing post contents using each model's own tokenizer and masking tokens with a probability of 15\%. We use a batch size of 32 samples and train the models for one epoch on one Tesla P100 GPU with 16 GB of VRAM.

As regards the bilingual setting, we use \mbert\, as our baseline. We also use an MLM-enhanced version of it, ``\imbert'',\footnote{\url{https://huggingface.co/pgajo/incel-mbert}}
obtained by further pre-training \mbert\, on $500k$ posts sampled from \itforum\, and $500k$ posts sampled from \enforum, for a total of $1M$ posts in Italian and English \cite{gajo2023identification}.

\begin{table}[t]
  \caption{Incel corpora class distribution \cite{gajo2023identification}.}
  \label{tab:incel-corpora-distributions}
  \centering
  \begin{tabular}{l|cccc}
    \hline
    \bf Corpus                & \bf Misogyny & \bf Racism & \bf Both & \bf  Neither \\
    \hline
    \dsENclassificationtrain\,	       &  806 & 630 & 46 & 2,160 \\
    \dsENclassificationdev 	           &  173 & 130 & 13 & 464 \\
    \dsENclassificationtest 	       &  160 & 125 & 7  & 489 \\
    \dsITclassification$_{\mbox{te}}$  &  187 &   8 & 5  & 300 \\
    \hline
    \end{tabular}
\end{table}

\begin{table*}[t]
  \centering
  \caption{Performance when fine-tuning the monolingual models on Italian-only corpora. Epochs (e) selected based on validation F$_1$. Best scores in bold, second-best underlined; \bs\, = corpus used for training.}
  \label{tab:italian-only-results}

  \begin{tabular}{l|c@{\hspace{1mm}}c@{\hspace{1mm}}c@{\hspace{1mm}}|c@{\hspace{1mm}}|ccc|ccc}
      & \rotatebox{90}{\hsdfb} & \rotatebox{90}{\hsdtw} & \rotatebox{90}{\ami} & \bf (e)
      & \bf F$_{1~val}$ & \bf R$_{val}$ & \bf P$_{val}$ & \bf F$_{1~test}$& \bf R$_{test}$ & \bf P$_{test}$ \\
        \hline
        \multirow{7}{*}[5pt]{\rotatebox[origin=c]{90}{\begin{minipage}{1.7cm}\umbert\end{minipage}}}
        &  \bs  &      &      &      5 &      0.855$\pm$0.003 &     0.868 &       0.843 &       0.696$\pm$0.010 & \bf  0.879 &       0.576 \\ % 27
        &       &  \bs &      &      4 &      0.754$\pm$0.004 &     0.800 &       0.713 &       0.432$\pm$0.060 &      0.319 &       0.685 \\ % 28
        &       &      &  \bs &      4 &  \uline{0.914$\pm$0.004}& \uline{0.931}&  \bf  0.899 &       0.569$\pm$0.031 &      0.520 &       0.631 \\ % 29
        &  \bs  &  \bs &      &      4 &      0.788$\pm$0.006 &     0.824 &       0.755 &       0.666$\pm$0.024 &      0.758 &       0.595 \\ % 30
        &  \bs  &      &  \bs &      5 &      0.883$\pm$0.004 &     0.900 &       0.867 &   \uline{0.697$\pm$0.019}&      0.747 &       0.653 \\ % 31
        &       &  \bs &  \bs &      5 &      0.828$\pm$0.003 &     0.844 &       0.814 &       0.596$\pm$0.017 &      0.526 &   \uline{0.688}\\ % 32
        &  \bs  &  \bs &  \bs &      5 &      0.822$\pm$0.003 &     0.836 &       0.808 &       0.680$\pm$0.016 &      0.692 &       0.671 \\ % 33
        \hline
        \multirow{7}{*}[10pt]{\rotatebox[origin=c]{90}{\begin{minipage}{2.6cm} \iumbert\end{minipage}}}
        &  \bs  &      &      &      5 &      0.867$\pm$0.006 &     0.887 &       0.848 &  \bf  0.705$\pm$0.009 &  \uline{0.870}&       0.593 \\ % 27
        &       &  \bs &      &      4 &      0.756$\pm$0.002 &     0.810 &       0.708 &       0.403$\pm$0.024 &      0.285 &       0.692 \\ % 28
        &       &      &  \bs &      4 & \bf  0.918$\pm$0.001 & \bf 0.946 &   \uline{0.891}&       0.652$\pm$0.031 &      0.608 &       0.705 \\ % 29
        &  \bs  &  \bs &      &      4 &      0.790$\pm$0.003 &     0.831 &       0.754 &       0.660$\pm$0.014 &      0.696 &       0.627 \\ % 30
        &  \bs  &      &  \bs &      5 &      0.886$\pm$0.002 &     0.901 &       0.872 &       0.704$\pm$0.005 &      0.732 &       0.678 \\ % 31
        &       &  \bs &  \bs &      2 &      0.831$\pm$0.003 &     0.866 &       0.799 &       0.648$\pm$0.011 &      0.544 &  \bf  0.802 \\ % 32
        &  \bs  &  \bs &  \bs &      5 &      0.828$\pm$0.003 &     0.853 &       0.804 &       0.699$\pm$0.029 &      0.718 &       0.682 \\ % 33
        \hline
        \hline
        \multirow{7}{*}[8pt]{\rotatebox[origin=c]{90}{\begin{minipage}{1.7cm}\albert\end{minipage}}}
        &  \bs  &      &      &      4 &      0.850$\pm$0.003 &     0.899 &       0.807 &       0.683$\pm$0.006 & \bf  0.941 &       0.537 \\ % 27
        &       &  \bs &      &      1 &      0.752$\pm$0.006 &     0.817 &       0.698 &       0.520$\pm$0.089 &      0.426 &   \uline{0.716}\\ % 28
        &       &      &  \bs &      2 & \uline{0.907$\pm$0.004} & \bf 0.952 &  \uline{0.866} &       0.528$\pm$0.022 &      0.517 &       0.542 \\ % 29
        &  \bs  &  \bs &      &      2 &      0.775$\pm$0.003 &     0.803 &       0.750 &       0.695$\pm$0.007 &      0.786 &       0.623 \\ % 30
        &  \bs  &      &  \bs &      3 &      0.879$\pm$0.003 &     0.918 &       0.843 &  \uline{0.705$\pm$0.011} &      0.803 &       0.629 \\ % 31
        &       &  \bs &  \bs &      3 &      0.820$\pm$0.001 &     0.888 &       0.762 &       0.652$\pm$0.018 &      0.645 &       0.660 \\ % 32
        &  \bs  &  \bs &  \bs &      2 &      0.808$\pm$0.011 &     0.872 &       0.753 &       0.684$\pm$0.015 &      0.821 &       0.587 \\ % 33
        \hline
        \multirow{7}{*}[13pt]{\rotatebox[origin=c]{90}{\begin{minipage}{2.6cm} \ialbert\end{minipage}}}
        &  \bs  &      &      &      5 &      0.847$\pm$0.005 &     0.863 &       0.831 &  \bf  0.707$\pm$0.007 & \uline{0.791} &       0.639 \\ % 27
        &       &  \bs &      &      1 &      0.748$\pm$0.002 &     0.785 &       0.715 &       0.506$\pm$0.035 &      0.370 &  \bf  0.805 \\ % 28
        &       &      &  \bs &      5 & \bf  0.912$\pm$0.003 & \uline{0.930}&  \bf  0.895 &       0.617$\pm$0.018 &      0.562 &       0.685 \\ % 29
        &  \bs  &  \bs &      &      2 &      0.771$\pm$0.004 &     0.791 &       0.752 &       0.673$\pm$0.016 &      0.721 &       0.632 \\ % 30
        &  \bs  &      &  \bs &      5 &      0.873$\pm$0.003 &     0.888 &       0.858 &       0.668$\pm$0.014 &      0.663 &       0.674 \\ % 31
        &       &  \bs &  \bs &      1 &      0.818$\pm$0.004 &     0.864 &       0.776 &       0.656$\pm$0.007 &      0.593 &       0.736 \\ % 32
        &  \bs  &  \bs &  \bs &      4 &      0.800$\pm$0.009 &     0.828 &       0.773 &       0.688$\pm$0.017 &      0.747 &       0.639 \\ % 33
        \hline
    \end{tabular}
\end{table*}

\begin{table*}[t]
  \centering
  % \footnotesize
  \caption{Performance when fine-tuning the multilingual models on mono- and bilingual corpora combinations. Epochs (e) selected based on validation F$_1$. Best scores in bold; \bs\, = corpus used for training.}
  \label{tab:multilingual-results}

  \begin{tabular}{l|l|c@{\hspace{1mm}}c@{\hspace{1mm}}c@{\hspace{1mm}}|c@{\hspace{1mm}}|c@{\hspace{1mm}}|ccc|ccc}
    \multicolumn{1}{c}{} && \rotatebox{90}{\hsdfb} & \rotatebox{90}{\hsdtw} & \rotatebox{90}{\ami} & \rotatebox{90}{\dsENclassification} & \bf (e)
    & \bf F$_{1~val}$ & \bf R$_{val}$ & \bf P$_{val}$ & \bf F$_{1~test}$& \bf R$_{test}$ & \bf P$_{test}$ \\
        \hline
            \multirow{15}{*}[10pt]{\rotatebox[origin=c]{90}{\begin{minipage}{1.5cm}mBERT\end{minipage}}}
        &\multirow{8}{*}[0pt]{\rotatebox[origin=c]{90}{Monolingual}}&  \bs  &      &      &      &    4 &      0.807$\pm$0.008 &     0.846 &       0.775 &       0.651$\pm$0.013 &      0.891 &       0.516 \\ % 27
        &&       &  \bs &      &      &    4 &      0.717$\pm$0.012 &     0.745 &       0.693 &       0.493$\pm$0.037 &      0.455 &       0.540 \\ % 28
        &&       &      &  \bs &      &    5 & \bf  0.885$\pm$0.003 & \bf 0.890 & \bf   0.881 &       0.425$\pm$0.034 &      0.384 &       0.479 \\ % 29
        &&  \bs  &  \bs &      &      &    2 &      0.732$\pm$0.014 &     0.743 &       0.724 &       0.619$\pm$0.034 &      0.711 &       0.552 \\ % 30
        &&  \bs  &      &  \bs &      &    3 &      0.844$\pm$0.002 &     0.873 &       0.818 &       0.639$\pm$0.023 &      0.747 &       0.560 \\ % 31
        &&       &  \bs &  \bs &      &    3 &      0.789$\pm$0.008 &     0.830 &       0.754 &       0.560$\pm$0.023 &      0.621 &       0.516 \\ % 32
        &&  \bs  &  \bs &  \bs &      &    5 &      0.784$\pm$0.002 &     0.793 &       0.775 &       0.600$\pm$0.014 &      0.634 &       0.569 \\ % 33
        &&       &      &      &  \bs &    5 &      0.846$\pm$0.010 &     0.854 &       0.837 &       0.465$\pm$0.046 &      0.345 & \bf   0.725 \\ % 17
        \cline{2-13}
        &\multirow{7}{*}[0pt]{\rotatebox[origin=c]{90}{Bilingual}}&  \bs  &      &      &  \bs &    3 &      0.841$\pm$0.004 &     0.852 &       0.832 & \bf   0.688$\pm$0.006 & \bf  0.921 &       0.549 \\ % 34
        &&       &  \bs &      &  \bs &    3 &      0.846$\pm$0.002 &     0.866 &       0.827 &       0.529$\pm$0.041 &      0.482 &       0.588 \\ % 35
        &&       &      &  \bs &  \bs &    5 &      0.844$\pm$0.007 &     0.849 &       0.838 &       0.634$\pm$0.023 &      0.587 &       0.692 \\ % 36
        &&  \bs  &  \bs &      &  \bs &    4 &      0.844$\pm$0.006 &     0.844 &       0.844 &       0.616$\pm$0.028 &      0.675 &       0.568 \\ % 37
        &&  \bs  &      &  \bs &  \bs &    5 &      0.842$\pm$0.004 &     0.844 &       0.840 &       0.676$\pm$0.012 &      0.801 &       0.585 \\ % 38
        &&       &  \bs &  \bs &  \bs &    4 &      0.847$\pm$0.008 &     0.841 &       0.853 &       0.570$\pm$0.048 &      0.535 &       0.620 \\ % 39
        &&  \bs  &  \bs &  \bs &  \bs &    5 &      0.837$\pm$0.008 &     0.829 &       0.845 &       0.613$\pm$0.019 &      0.639 &       0.590 \\ % 40
        \hline
        \hline
            \multirow{15}{*}[10pt]{\rotatebox[origin=c]{90}{\begin{minipage}{2.2cm}Incel mBERT\end{minipage}}}
        &\multirow{8}{*}[0pt]{\rotatebox[origin=c]{90}{Monolingual}}&  \bs  &      &      &      &    1 &      0.817$\pm$0.009 &     0.865 &       0.777 &       0.668$\pm$0.016 &      0.841 &       0.557 \\ % 27
        &&       &  \bs &      &      &    5 &      0.727$\pm$0.006 &     0.757 &       0.701 &       0.461$\pm$0.032 &      0.379 &       0.589 \\ % 28
        &&       &      &  \bs &      &    4 & \bf  0.895$\pm$0.007 & \bf 0.912 & \bf   0.879 &       0.574$\pm$0.047 &      0.511 &       0.666 \\ % 29
        &&  \bs  &  \bs &      &      &    3 &      0.747$\pm$0.007 &     0.774 &       0.723 &       0.605$\pm$0.015 &      0.640 &       0.574 \\ % 30
        &&  \bs  &      &  \bs &      &    3 &      0.854$\pm$0.004 &     0.896 &       0.816 &       0.654$\pm$0.025 &      0.752 &       0.583 \\ % 31
        &&       &  \bs &  \bs &      &    4 &      0.802$\pm$0.003 &     0.840 &       0.767 &       0.645$\pm$0.019 &      0.655 &       0.639 \\ % 32
        &&  \bs  &  \bs &  \bs &      &    3 &      0.799$\pm$0.004 &     0.825 &       0.774 &       0.648$\pm$0.022 &      0.644 &       0.653 \\ % 33
        &&       &      &      &  \bs &    3 &      0.855$\pm$0.003 &     0.877 &       0.834 &       0.516$\pm$0.071 &      0.386 & \bf   0.807 \\ % 17
        \cline{2-13}
        &\multirow{7}{*}[0pt]{\rotatebox[origin=c]{90}{Bilingual}}&  \bs  &      &      &  \bs &    5 &      0.859$\pm$0.010 &     0.853 &       0.864 &       0.708$\pm$0.007 & \bf  0.889 &       0.588 \\ % 34
        &&       &  \bs &      &  \bs &    2 &      0.861$\pm$0.015 &     0.866 &       0.856 &       0.615$\pm$0.025 &      0.558 &       0.690 \\ % 35
        &&       &      &  \bs &  \bs &    4 &      0.853$\pm$0.009 &     0.863 &       0.844 & \bf   0.722$\pm$0.028 &      0.704 &       0.746 \\ % 36
        &&  \bs  &  \bs &      &  \bs &    5 &      0.857$\pm$0.007 &     0.855 &       0.859 &       0.679$\pm$0.014 &      0.731 &       0.635 \\ % 37
        &&  \bs  &      &  \bs &  \bs &    4 &      0.856$\pm$0.009 &     0.857 &       0.856 &       0.689$\pm$0.011 &      0.707 &       0.673 \\ % 38
        &&       &  \bs &  \bs &  \bs &    5 &      0.850$\pm$0.007 &     0.839 &       0.860 &       0.644$\pm$0.010 &      0.580 &       0.725 \\ % 39
        &&  \bs  &  \bs &  \bs &  \bs &    5 &      0.869$\pm$0.003 &     0.878 &       0.861 &       0.700$\pm$0.013 &      0.702 &       0.698 \\ % 40
        \hline
    \end{tabular}
\end{table*}




\section{Experiments and Results}
\label{sec:exps}

We approach the task of identifying hate speech as a binary classification problem, where a post can either be hateful or not. We train each model five times on all possible combinations of the
corpora listed in Tables~\ref{tab:existing-corpora-distributions} and \ref{tab:incel-corpora-distributions} in order to make our results more reliable and diminish the effect of the random initialization of the models. In the monolingual Italian setting we never use \dsENclassification, while it is always included when training the multilingual models in the bilingual setting. We select the number of epochs based on the convergence of the performance on the validation
set, in terms of F$_1$-measure on the positive class. For each corpus combination, the training and validation sets are the union of the individual training and validation sets of each merged corpus. The models are then evaluated on the \dsITclassification\, test set.

\paragraph{Monolingual setting}
Table~\ref{tab:italian-only-results} shows the performance in terms of precision, recall and F$_1$-measure for the Italian-only models and corpora combinations.
The top-performing model is \ialbert, which achieves a test F$_1$ of 0.707 when training solely on \hsdfb. Compared to \albert, this represents an improvement of 2.4 points. To a lesser degree, the same can be observed with regard to \iumbert\, and \umbert\, (+0.9 F$_1$ points), when using the same combination. In both cases, this shows that pre-training \albert\, and \umbert\, using MLM on Italian posts extracted from \itforum\, is effective in improving their performance.

The worst results are obtained when training solely on \hsdtw, with \ialbert\, and \iumbert\, performing worse than \umbert\, and \albert, showing an opposite trend to the one observed when training on \hsdfb.
The validation scores are also lower for \hsdtw\, combinations, compared to combinations including \hsdfb, showing that the models have a harder time learning from \hsdtw. This is coherent with the results obtained by teams participating in the two HaSpeeDe shared tasks~\cite{boscoOverviewEVALITA2018,basileEVALITA2020Overview} and with the fact that \hsdfb's messages are ``longer and more
correct than those in Twitter, allowing systems (and humans too) to find more and more clear indications of the presence of HS''~\cite{boscoOverviewEVALITA2018}.
The fact that messages in \hsdfb\, are longer is also coherent with the Italian incel models performing better than the vanilla models when training on \hsdfb, since \itforum\, on average contains rather long posts
($\sim$53 avg. tokens),\footnote{Obtained with BertTokenizer: \url{https://huggingface.co/docs/transformers/model_doc/bert\#transformers.BertTokenizer}} unlike Twitter corpora, which were limited to 280 characters per tweet prior to 2023.
Finally, another element which might explain the lower performance when training on \hsdtw\, is that it contains hate speech against migrants, which might not be as relevant when it comes to \itforum, since racism is not all that prevalent in this forum, compared to misogyny.

As regards combining different Italian corpora, the strategy yields the highest performance for \albert\, and \umbert\, when training on both \hsdfb\, and \ami.
However, once the models are MLM-trained on \itforum, the performance decreases for some combinations, with MLM pre-training seemingly nullifying the improvements obtained by merging different corpora. Therefore, while some improvement can be observed by merging different corpora, MLM appears to be a more effective strategy for improving the performance of the models, although it requires greater computational resources.

\paragraph{Bilingual setting}
Table~\ref{tab:multilingual-results} reports the results for the bilingual setting.
Compared to the best combination using \mbert, which achieves a test F$_1$ of 0.688, the best combination using \imbert\, achieves a test F$_1$ of 0.722 (+3.4 F$_1$ points), which is also the highest score across both language settings. Just like in the monolingual setting, \mbert\, performs better when only training it on \hsdfb\, (in addition to \dsENclassification). Conversely, \imbert\, performs better when training on \ami\, and \dsENclassification. This is interesting, since the incorporation of the \ami\, corpus lowered the performance of all Italian-only models, compared to only training on \hsdfb. Since misogyny is the main way hate speech is expressed in \enforum\, (39.44\% of the instances in \dsENclassification\, are misogynous) and
\imbert\, was pre-trained using posts extracted from this forum, the performance boost could be due to the fact that the model is better at learning about misogynous language compared to \mbert\, and the Italian-only models.

On average, the lowest performance is achieved when training separately on \dsENclassification\, and on the Italian corpora (monolingual rows in Table~\ref{tab:multilingual-results}). When using bilingual data, the worst results are obtained when training on \hsdtw\, and combinations containing it, coherently with the results in the monolingual settings shown in \mbox{Table~\ref{tab:italian-only-results}}.

For almost all combinations of Italian corpora, performance increases once \dsENclassification\, is added to the training data, i.e.\, bilingual data leads to better performance.

\paragraph{Monolingual vs.\ bilingual}
The results of our experiments show that the highest performance is not obtained by fine-tuning on the Italian-only corpus combinations, but on the bilingual ones. Indeed, for four bilingual corpus combinations out of seven, \imbert's performance is higher than all other models.
The combinations for which \imbert\, does not beat all the others are \hsdfb+\hsdtw, \hsdfb+\ami\, and \hsdtw+\ami.

Since mBERT was originally pre-trained in 104 languages and \albert\, and \umbert\, were pre-trained only on Italian corpora, the fact that \imbert\, can outperform them by pre-training on just $1M$ bilingual instances is rather unexpected.
Even more interesting is the fact that, although we are testing on an entirely Italian corpus, \imbert\, also outperforms \ialbert\, and \iumbert. Therefore, in the approached scenarios, using bilingual instances to pre-train a multilingual model using MLM yields higher performance than pre-training Italian models only on Italian posts. Furthermore, the number of Italian posts used to train \ialbert\, and \iumbert\, is $627k$, which is greater than the $500k$ Italian posts used for \imbert.

As such, we could arguably conclude that the model is learning to spot hate speech more effectively in \dsITclassification\, by learning language-agnostic incel concepts, since \imbert\, is pre-trained on posts extracted from two incel forums in two different languages.
Although the two considered incel communities are distinct, the hateful Red Pill ideology has spread internationally and is shared by both. This could explain why \imbert\, performs better than the Italian-only models: the model might be learning about incel hate speech by paying more attention to the sociological concepts underlying the language, and putting less focus on purely linguistic features, ultimately improving its performance.

\begin{table}
    \centering
    \caption{Performance of our best model on on the different subclasses of the \dsITclassification\, test corpus.
    }
    \label{tab:misogyny-racism-subsets-statistics}
  \begin{tabular}{lcccr}
    \hline
    \bf Class & \bf Precision & \bf Recall & \bf F$_1$ & \bf Inst. \\
    \hline
    None & 0.806 & 0.857 & 0.830 & 300 \\
    Misogyny & 0.746 & 0.674 & 0.708 & 187 \\
    Racism & 1.000 & 0.875 & 0.933 & 8 \\
    Both & 1.000 & 1.000 & 1.000 & 5 \\
    \hline
    % Accuracy & 0.790 & 0.790 & 0.790 & 0.790 \\
    Macro & 0.888 & 0.851 & 0.868 & 500 \\
    % Wtd. F$_1$ & 0.788 & 0.790 & 0.788 & 500 \\
    \hline
    \end{tabular}

\end{table}

\paragraph{Performance on misogyny/racism subclasses}

Table~\ref{tab:misogyny-racism-subsets-statistics} reports the performance of the best model ---the one obtained by fine-tuning \imbert\, on \dsENclassification\, $\cup$ \ami--- on the individual misogyny and racism labels of the \dsITclassification\, test set.
When looking at the difference between the performance on misogyny vs.\ racism, we notice a stark difference, with racism having perfect precision and a much higher F$_1$. Expectedly, this also translates into the instances that are both misogynous and racist, with perfect precision and recall.
The explanation for the racist instances being much easier to detect is two-fold:
\Ni the number of instances which are only racist is much smaller (8 vs. 187) and
\Nii  compared to the misogyny expressed by \itforum\, users, the racism is much more explicit and simpler to identify.
This can be seen in the examples in Table~\ref{tab:examples}, which display explicit language in the first four instances, which contain racism. Here, the model can easily detect hate, even though users might even attempt to auto-censor themselves by substituting letters with numbers, as in example \#1 (most likely in order to bypass automatic forum filters). Conversely, the misogyny in the last two samples is much more implicit, with the model failing to detect misogyny in sample \#5.


\begin{table}
  \centering
  \caption{Examples of racist and misogynous posts from \dsITclassification, with gold annotation and \imbert\, prediction labels.}
  \label{tab:examples}
  \begin{tabular}{p{4.8cm}@{\hspace{1mm}}|c@{\hspace{1mm}}|c@{\hspace{1mm}}}
  \hline
  \bf Post & \bf Gold & \bf Pred. \\
  \hline
  Compagno le n3gr3 sono oggettivamente brutte, le asiatiche lo sono in media - ma quelle belle lo sono davvero e staccano di misura le cosiddette belle nostrane. & Both & Both \\
  \hline
  No perchè sessualmente mi fanno schifo le negre e i trans (più questi ultimi eh). & Both & Both \\
  \hline
  Ora capisco perché non scopava, curry percepito anche se non è curry, currycel in pratica. & Rac. & Rac. \\
  \hline
  Che dire allora dei terroni quasi tutti arabi quindi negri e di quei rari bianchi europei che provengono da altre nazioni europee? La mafia cioè i terroni stanno importando queste merde in massa per farci terronizzare e negrizzare come loro. & Rac. & Rac. \\
  \hline
  le 8+ sono davvero rare. tuttavia, dal 5 in su si atteggiano tutte come fossero modelle... & Mis. & None \\
  \hline
  Probabilmente la vedrai tra qualche settimana ad ipergamare con qualche architetto & Mis. & Mis. \\
  \hline
  \end{tabular}
\end{table}

\section{Conclusions}
\label{sec:conclusions}

In this paper, we have presented an approach to improve the performance of hate speech detection models in Italian incel posts.
Our experiments show that domain-adapting transformer models to the contents of incel forums boosts their performance when predicting the hatefulness of incel forum posts, both when using Italian-only and multilingual models. The increase in performance obtained through MLM pre-training is particularly high when using bilingual training data with \mbert, which might indicate that the model is learning about incel hate speech by learning language-agnostic incel concepts.
We have also shown that for the base Italian models (\albert\, and \umbert) fine-tuning on combinations of different Italian corpora can lead to a boost in performance. However, this performance boost is nullified after MLM pre-training, which appears to be a more effective strategy for improving the performance of the models. When looking at racism vs.\ misogyny identification in posts extracted from \itforum, the former appears to be much easier to detect. This seems due to the fact that racist language is much more explicit than misogynous language in the scrutinized forum, but further research is needed to ascertain such a supposition.

In future work, we plan to experiment with different resources for MLM pre-training, using corpora in different languages, since it seems multilingual models such as \mbert\, are capable of learning about hate speech in a language-agnostic way from multiple languages. In addition, with more computational resources, larger corpora and more training epochs could be used to further improve the performance of the models. Lastly, further experiments can be carried out as regards the performance of the scrutinized models on the individual sub-tasks of misogyny and racism identification, respectively.

\bibliography{clic-it-2023.bib}

\end{document}
